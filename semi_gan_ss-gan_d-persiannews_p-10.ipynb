{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "semi_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamardian/digikalamag/blob/main/semi_gan_ss-gan_d-persiannews_p-10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVzghhQznhMw",
        "outputId": "bff9ed66-9956-4847-8076-878dc7e35254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.3.2\n",
            "  Downloading transformers-4.3.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (2022.6.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (4.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (3.7.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 47.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (21.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.2) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.2) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.2) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (2022.5.18.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.2) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=23876f218c97d1bbfb9ff7b386da50e441b546c93c718b29744f8c16d98d9dbe\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.3.2\n",
            "rm: cannot remove './semi_supervised_learning_with_gan': No such file or directory\n",
            "Cloning into 'semi_supervised_learning_with_gan'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 46 (delta 23), reused 35 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (46/46), done.\n",
            "Dataset : persiannews \n",
            "Percentage : 0.1\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Cloning into 'persiannews'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 0), reused 5 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), done.\n",
            "./persiannews/train.csv\n",
            "./persiannews/test.csv\n",
            "Downloading: 100% 440/440 [00:00<00:00, 562kB/s]\n",
            "Downloading: 100% 654M/654M [00:08<00:00, 73.1MB/s]\n",
            "Downloading: 100% 1.20M/1.20M [00:00<00:00, 6.04MB/s]\n",
            "[0, 1, 2, 3, 4, 5, 6, 7]\n",
            "train_examples :  13314\n",
            "labeled_data_const :  1331\n",
            "labeled_examples :  1331\n",
            "unlabeled_examples :  11983\n",
            "\n",
            "======== Epoch 1 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:19.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:39.\n",
            "  Batch    30  of    250.    Elapsed: 0:00:58.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:19.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:39.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:00.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:21.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:42.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:03.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:24.\n",
            "  Batch   110  of    250.    Elapsed: 0:03:46.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:08.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:30.\n",
            "  Batch   140  of    250.    Elapsed: 0:04:52.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:14.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:36.\n",
            "  Batch   170  of    250.    Elapsed: 0:05:59.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:21.\n",
            "  Batch   190  of    250.    Elapsed: 0:06:44.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:06.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:29.\n",
            "  Batch   220  of    250.    Elapsed: 0:07:51.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:14.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:36.\n",
            "\n",
            "  Average training loss generetor: 0.688\n",
            "  Average training loss discriminator: 1.275\n",
            "  Training epcoh took: 0:08:58\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.954\n",
            "   epoch      acc\n",
            "0      1  0.95438\n",
            "  Test Loss: 0.167\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 2 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:30.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:15.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n",
            "  Batch    80  of    250.    Elapsed: 0:03:00.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:22.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:45.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:07.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:29.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:52.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:14.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:37.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:59.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:22.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:44.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:06.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:29.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:51.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:14.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:36.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:59.\n",
            "\n",
            "  Average training loss generetor: 0.706\n",
            "  Average training loss discriminator: 0.772\n",
            "  Training epcoh took: 0:09:20\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.958\n",
            "   epoch       acc\n",
            "0      1  0.954380\n",
            "1      2  0.958029\n",
            "  Test Loss: 0.196\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 3 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:30.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:15.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n",
            "  Batch    80  of    250.    Elapsed: 0:03:00.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:22.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:44.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:07.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:29.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:51.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:14.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:36.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:59.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:21.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:44.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:06.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:29.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:51.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:14.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:36.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:59.\n",
            "\n",
            "  Average training loss generetor: 0.700\n",
            "  Average training loss discriminator: 0.747\n",
            "  Training epcoh took: 0:09:20\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.954\n",
            "   epoch       acc\n",
            "0      1  0.954380\n",
            "1      2  0.958029\n",
            "2      3  0.954380\n",
            "  Test Loss: 0.233\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 4 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:29.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:14.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:59.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:21.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:44.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:06.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:29.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:51.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:14.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:36.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:59.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:22.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:44.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:07.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:29.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:51.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:14.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:36.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:59.\n",
            "\n",
            "  Average training loss generetor: 0.700\n",
            "  Average training loss discriminator: 0.729\n",
            "  Training epcoh took: 0:09:20\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.935\n",
            "   epoch       acc\n",
            "0      1  0.954380\n",
            "1      2  0.958029\n",
            "2      3  0.954380\n",
            "3      4  0.934915\n",
            "  Test Loss: 0.377\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 5 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:30.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:15.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:59.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:22.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:44.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:07.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:29.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:51.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:14.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:36.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:59.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:21.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:43.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:06.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:28.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:51.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:13.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:35.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:58.\n",
            "\n",
            "  Average training loss generetor: 0.699\n",
            "  Average training loss discriminator: 0.720\n",
            "  Training epcoh took: 0:09:19\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.952\n",
            "   epoch       acc\n",
            "0      1  0.954380\n",
            "1      2  0.958029\n",
            "2      3  0.954380\n",
            "3      4  0.934915\n",
            "4      5  0.951946\n",
            "  Test Loss: 0.267\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 6 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:30.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:14.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:59.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:22.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:44.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:06.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:29.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:51.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:14.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:36.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:58.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:21.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:43.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:06.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:28.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:51.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:13.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:35.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:58.\n",
            "\n",
            "  Average training loss generetor: 0.700\n",
            "  Average training loss discriminator: 0.708\n",
            "  Training epcoh took: 0:09:20\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.952\n",
            "   epoch       acc\n",
            "0      1  0.954380\n",
            "1      2  0.958029\n",
            "2      3  0.954380\n",
            "3      4  0.934915\n",
            "4      5  0.951946\n",
            "5      6  0.951946\n",
            "  Test Loss: 0.277\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 7 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:23.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:08.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:30.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:53.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:15.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:38.\n",
            "  Batch    80  of    250.    Elapsed: 0:03:00.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:23.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:45.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:08.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:30.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:53.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:15.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:38.\n",
            "  Batch   160  of    250.    Elapsed: 0:06:00.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:23.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:45.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:07.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:30.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:52.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:15.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:37.\n",
            "  Batch   240  of    250.    Elapsed: 0:09:00.\n",
            "\n",
            "  Average training loss generetor: 0.699\n",
            "  Average training loss discriminator: 0.712\n",
            "  Training epcoh took: 0:09:21\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.939\n",
            "   epoch       acc\n",
            "0      1  0.954380\n",
            "1      2  0.958029\n",
            "2      3  0.954380\n",
            "3      4  0.934915\n",
            "4      5  0.951946\n",
            "5      6  0.951946\n",
            "6      7  0.938564\n",
            "  Test Loss: 0.338\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 8 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:30.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:15.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n",
            "  Batch    80  of    250.    Elapsed: 0:03:00.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:22.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:45.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:07.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:30.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:52.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:15.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:37.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:59.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:22.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:44.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:07.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:29.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:52.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:14.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:37.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:59.\n",
            "\n",
            "  Average training loss generetor: 0.700\n",
            "  Average training loss discriminator: 0.761\n",
            "  Training epcoh took: 0:09:21\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.937\n",
            "   epoch       acc\n",
            "0      1  0.954380\n",
            "1      2  0.958029\n",
            "2      3  0.954380\n",
            "3      4  0.934915\n",
            "4      5  0.951946\n",
            "5      6  0.951946\n",
            "6      7  0.938564\n",
            "7      8  0.937348\n",
            "  Test Loss: 0.362\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 9 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:30.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:15.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n",
            "  Batch    80  of    250.    Elapsed: 0:03:00.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:22.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:44.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:07.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:29.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:52.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:14.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:37.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:59.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:21.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:44.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:06.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:29.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:51.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:13.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:36.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:58.\n",
            "\n",
            "  Average training loss generetor: 0.699\n",
            "  Average training loss discriminator: 0.726\n",
            "  Training epcoh took: 0:09:20\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.936\n",
            "   epoch       acc\n",
            "0      1  0.954380\n",
            "1      2  0.958029\n",
            "2      3  0.954380\n",
            "3      4  0.934915\n",
            "4      5  0.951946\n",
            "5      6  0.951946\n",
            "6      7  0.938564\n",
            "7      8  0.937348\n",
            "8      9  0.936131\n",
            "  Test Loss: 0.408\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 10 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:30.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:15.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n",
            "  Batch    80  of    250.    Elapsed: 0:03:00.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:22.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:45.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:07.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:29.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:52.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:14.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:37.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:59.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:22.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:44.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:07.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:29.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:52.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:14.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:36.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:59.\n",
            "\n",
            "  Average training loss generetor: 0.699\n",
            "  Average training loss discriminator: 0.745\n",
            "  Training epcoh took: 0:09:21\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.908\n",
            "   epoch       acc\n",
            "0      1  0.954380\n",
            "1      2  0.958029\n",
            "2      3  0.954380\n",
            "3      4  0.934915\n",
            "4      5  0.951946\n",
            "5      6  0.951946\n",
            "6      7  0.938564\n",
            "7      8  0.937348\n",
            "8      9  0.936131\n",
            "9     10  0.907543\n",
            "  Test Loss: 0.574\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 11 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:30.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:14.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:59.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:22.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:44.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:07.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:29.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:51.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:14.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:36.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:59.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:21.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:44.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:06.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:28.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:51.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:13.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:35.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:58.\n",
            "\n",
            "  Average training loss generetor: 0.698\n",
            "  Average training loss discriminator: 0.784\n",
            "  Training epcoh took: 0:09:20\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.941\n",
            "    epoch       acc\n",
            "0       1  0.954380\n",
            "1       2  0.958029\n",
            "2       3  0.954380\n",
            "3       4  0.934915\n",
            "4       5  0.951946\n",
            "5       6  0.951946\n",
            "6       7  0.938564\n",
            "7       8  0.937348\n",
            "8       9  0.936131\n",
            "9      10  0.907543\n",
            "10     11  0.940998\n",
            "  Test Loss: 0.291\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 12 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:30.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:15.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n",
            "  Batch    80  of    250.    Elapsed: 0:03:00.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:22.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:45.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:07.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:30.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:52.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:14.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:37.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:59.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:22.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:45.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:07.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:29.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:52.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:14.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:37.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:59.\n",
            "\n",
            "  Average training loss generetor: 0.698\n",
            "  Average training loss discriminator: 0.705\n",
            "  Training epcoh took: 0:09:21\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.950\n",
            "    epoch       acc\n",
            "0       1  0.954380\n",
            "1       2  0.958029\n",
            "2       3  0.954380\n",
            "3       4  0.934915\n",
            "4       5  0.951946\n",
            "5       6  0.951946\n",
            "6       7  0.938564\n",
            "7       8  0.937348\n",
            "8       9  0.936131\n",
            "9      10  0.907543\n",
            "10     11  0.940998\n",
            "11     12  0.950122\n",
            "  Test Loss: 0.343\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 13 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:30.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:15.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n",
            "  Batch    80  of    250.    Elapsed: 0:03:00.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:22.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:45.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:07.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:30.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:52.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:15.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:37.\n",
            "  Batch   160  of    250.    Elapsed: 0:06:00.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:22.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:45.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:07.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:30.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:52.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:14.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:37.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:59.\n",
            "\n",
            "  Average training loss generetor: 0.698\n",
            "  Average training loss discriminator: 0.701\n",
            "  Training epcoh took: 0:09:21\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.949\n",
            "    epoch       acc\n",
            "0       1  0.954380\n",
            "1       2  0.958029\n",
            "2       3  0.954380\n",
            "3       4  0.934915\n",
            "4       5  0.951946\n",
            "5       6  0.951946\n",
            "6       7  0.938564\n",
            "7       8  0.937348\n",
            "8       9  0.936131\n",
            "9      10  0.907543\n",
            "10     11  0.940998\n",
            "11     12  0.950122\n",
            "12     13  0.948905\n",
            "  Test Loss: 0.365\n",
            "  Test took: 0:00:12\n",
            "\n",
            "======== Epoch 14 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:30.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:15.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:38.\n",
            "  Batch    80  of    250.    Elapsed: 0:03:00.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:23.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:45.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:08.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:30.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:53.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:15.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:38.\n",
            "  Batch   160  of    250.    Elapsed: 0:06:00.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:23.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:45.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:08.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:31.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:53.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:16.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:38.\n",
            "  Batch   240  of    250.    Elapsed: 0:09:01.\n",
            "\n",
            "  Average training loss generetor: 0.699\n",
            "  Average training loss discriminator: 0.772\n",
            "  Training epcoh took: 0:09:22\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.937\n",
            "    epoch       acc\n",
            "0       1  0.954380\n",
            "1       2  0.958029\n",
            "2       3  0.954380\n",
            "3       4  0.934915\n",
            "4       5  0.951946\n",
            "5       6  0.951946\n",
            "6       7  0.938564\n",
            "7       8  0.937348\n",
            "8       9  0.936131\n",
            "9      10  0.907543\n",
            "10     11  0.940998\n",
            "11     12  0.950122\n",
            "12     13  0.948905\n",
            "13     14  0.937348\n",
            "  Test Loss: 0.385\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 15 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:23.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:30.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:15.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n",
            "  Batch    80  of    250.    Elapsed: 0:03:00.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:22.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:44.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:07.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:29.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:52.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:14.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:36.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:59.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:21.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:43.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:06.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:28.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:51.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:13.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:36.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:58.\n",
            "\n",
            "  Average training loss generetor: 0.698\n",
            "  Average training loss discriminator: 0.715\n",
            "  Training epcoh took: 0:09:20\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.931\n",
            "    epoch       acc\n",
            "0       1  0.954380\n",
            "1       2  0.958029\n",
            "2       3  0.954380\n",
            "3       4  0.934915\n",
            "4       5  0.951946\n",
            "5       6  0.951946\n",
            "6       7  0.938564\n",
            "7       8  0.937348\n",
            "8       9  0.936131\n",
            "9      10  0.907543\n",
            "10     11  0.940998\n",
            "11     12  0.950122\n",
            "12     13  0.948905\n",
            "13     14  0.937348\n",
            "14     15  0.930657\n",
            "  Test Loss: 0.476\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 16 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:30.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:15.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n",
            "  Batch    80  of    250.    Elapsed: 0:03:00.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:22.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:44.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:07.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:29.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:51.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:14.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:36.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:59.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:21.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:43.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:06.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:28.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:51.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:13.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:36.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:58.\n",
            "\n",
            "  Average training loss generetor: 0.698\n",
            "  Average training loss discriminator: 0.719\n",
            "  Training epcoh took: 0:09:20\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.929\n",
            "    epoch       acc\n",
            "0       1  0.954380\n",
            "1       2  0.958029\n",
            "2       3  0.954380\n",
            "3       4  0.934915\n",
            "4       5  0.951946\n",
            "5       6  0.951946\n",
            "6       7  0.938564\n",
            "7       8  0.937348\n",
            "8       9  0.936131\n",
            "9      10  0.907543\n",
            "10     11  0.940998\n",
            "11     12  0.950122\n",
            "12     13  0.948905\n",
            "13     14  0.937348\n",
            "14     15  0.930657\n",
            "15     16  0.928832\n",
            "  Test Loss: 0.486\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 17 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:29.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:14.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:59.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:21.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:44.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:06.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:29.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:51.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:13.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:36.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:58.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:21.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:43.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:05.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:28.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:50.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:13.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:35.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:57.\n",
            "\n",
            "  Average training loss generetor: 0.698\n",
            "  Average training loss discriminator: 0.701\n",
            "  Training epcoh took: 0:09:19\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.934\n",
            "    epoch       acc\n",
            "0       1  0.954380\n",
            "1       2  0.958029\n",
            "2       3  0.954380\n",
            "3       4  0.934915\n",
            "4       5  0.951946\n",
            "5       6  0.951946\n",
            "6       7  0.938564\n",
            "7       8  0.937348\n",
            "8       9  0.936131\n",
            "9      10  0.907543\n",
            "10     11  0.940998\n",
            "11     12  0.950122\n",
            "12     13  0.948905\n",
            "13     14  0.937348\n",
            "14     15  0.930657\n",
            "15     16  0.928832\n",
            "16     17  0.933698\n",
            "  Test Loss: 0.464\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 18 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:29.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:14.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n",
            "  Batch    80  of    250.    Elapsed: 0:02:59.\n",
            "  Batch    90  of    250.    Elapsed: 0:03:21.\n",
            "  Batch   100  of    250.    Elapsed: 0:03:44.\n",
            "  Batch   110  of    250.    Elapsed: 0:04:06.\n",
            "  Batch   120  of    250.    Elapsed: 0:04:28.\n",
            "  Batch   130  of    250.    Elapsed: 0:04:51.\n",
            "  Batch   140  of    250.    Elapsed: 0:05:13.\n",
            "  Batch   150  of    250.    Elapsed: 0:05:36.\n",
            "  Batch   160  of    250.    Elapsed: 0:05:58.\n",
            "  Batch   170  of    250.    Elapsed: 0:06:20.\n",
            "  Batch   180  of    250.    Elapsed: 0:06:43.\n",
            "  Batch   190  of    250.    Elapsed: 0:07:05.\n",
            "  Batch   200  of    250.    Elapsed: 0:07:27.\n",
            "  Batch   210  of    250.    Elapsed: 0:07:50.\n",
            "  Batch   220  of    250.    Elapsed: 0:08:12.\n",
            "  Batch   230  of    250.    Elapsed: 0:08:34.\n",
            "  Batch   240  of    250.    Elapsed: 0:08:57.\n",
            "\n",
            "  Average training loss generetor: 0.698\n",
            "  Average training loss discriminator: 0.699\n",
            "  Training epcoh took: 0:09:18\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.936\n",
            "    epoch       acc\n",
            "0       1  0.954380\n",
            "1       2  0.958029\n",
            "2       3  0.954380\n",
            "3       4  0.934915\n",
            "4       5  0.951946\n",
            "5       6  0.951946\n",
            "6       7  0.938564\n",
            "7       8  0.937348\n",
            "8       9  0.936131\n",
            "9      10  0.907543\n",
            "10     11  0.940998\n",
            "11     12  0.950122\n",
            "12     13  0.948905\n",
            "13     14  0.937348\n",
            "14     15  0.930657\n",
            "15     16  0.928832\n",
            "16     17  0.933698\n",
            "17     18  0.936131\n",
            "  Test Loss: 0.468\n",
            "  Test took: 0:00:13\n",
            "\n",
            "======== Epoch 19 / 100 ========\n",
            "Training...\n",
            "  Batch    10  of    250.    Elapsed: 0:00:22.\n",
            "  Batch    20  of    250.    Elapsed: 0:00:45.\n",
            "  Batch    30  of    250.    Elapsed: 0:01:07.\n",
            "  Batch    40  of    250.    Elapsed: 0:01:29.\n",
            "  Batch    50  of    250.    Elapsed: 0:01:52.\n",
            "  Batch    60  of    250.    Elapsed: 0:02:14.\n",
            "  Batch    70  of    250.    Elapsed: 0:02:37.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.3.2\n",
        "!rm -r ./semi_supervised_learning_with_gan ;git clone https://github.com/iamardian/semi_supervised_learning_with_gan.git\n",
        "!python ./semi_supervised_learning_with_gan/ssgan_parsbert.py -d persiannews -p 0.1\n",
        "# !python ecgan_parsbert.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MxznXs1WoSc-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}